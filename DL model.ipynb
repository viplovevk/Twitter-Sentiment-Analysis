{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\School\\CSIT 321 FINAL YEAR PROJECT\\Datasetexploration\\tweetsSample.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>RelaxTense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again a beautiful morning is bursting ont...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@alexismmitchell dang, I accidentally unfollow...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was supposed to wake up at 6. woke up at 9. go...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@DH_NET Sorry to hear about that, Jen. Know ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kate is going to win! If she doesn't then i wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@serpah - I haz the geekflu too.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@donotwant interview went well! except i'll ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shall miss taping tomorrow...  darn school. hm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ages since last little Twit, Hello everyone i'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Everything tastes bland.  fever &amp;amp; flu-off ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This has been a dismal week.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>So tired of the same thing happening to me all...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>whywhywhy do Rookie Of The Year not come to En...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>My right knee is broken. Ok it's not literally...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ugh have to be up earlier  wish I was with him</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@kuttyedathi OMG, dont tell me u stirred tht h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rest in peace Miss Boberg . .  . . .  .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@zoecorkhill Its only cause I couldn't find an...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@TexMexfruitcake Sadly i didn't even save that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@JonathanRKnight Jon, r u heading to Atl now? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  Sentiment  RelaxTense\n",
       "0   Once again a beautiful morning is bursting ont...          0           0\n",
       "1   @alexismmitchell dang, I accidentally unfollow...          0           0\n",
       "2   was supposed to wake up at 6. woke up at 9. go...          0           4\n",
       "3   @DH_NET Sorry to hear about that, Jen. Know ho...          0           0\n",
       "4   Kate is going to win! If she doesn't then i wi...          0           2\n",
       "5                   @serpah - I haz the geekflu too.           0           0\n",
       "6   @donotwant interview went well! except i'll ha...          0           0\n",
       "7   shall miss taping tomorrow...  darn school. hm...          0           0\n",
       "8   ages since last little Twit, Hello everyone i'...          0           0\n",
       "9   Everything tastes bland.  fever &amp; flu-off ...          0           0\n",
       "10                      This has been a dismal week.           0           0\n",
       "11  So tired of the same thing happening to me all...          0           4\n",
       "12  whywhywhy do Rookie Of The Year not come to En...          0           0\n",
       "13  My right knee is broken. Ok it's not literally...          0           0\n",
       "14     Ugh have to be up earlier  wish I was with him          0           0\n",
       "15  @kuttyedathi OMG, dont tell me u stirred tht h...          0           0\n",
       "16           Rest in peace Miss Boberg . .  . . .  .           0           0\n",
       "17  @zoecorkhill Its only cause I couldn't find an...          0           4\n",
       "18  @TexMexfruitcake Sadly i didn't even save that...          0           0\n",
       "19  @JonathanRKnight Jon, r u heading to Atl now? ...          0           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    50000\n",
       "0    50000\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sampled 50% of each positive and negative from original kaggle dataset\n",
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80095\n",
       "2    14064\n",
       "4     5841\n",
       "Name: RelaxTense, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.RelaxTense.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the first binary model with a sample of 50000 positive tweets and 50000 negative tweets\n",
    "sentimentBinaryModelTrain = df[['text', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\foo_b\\anaconda3\\envs\\csci316\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "sentimentBinaryModelTrain.text = sentimentBinaryModelTrain.text.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       " Int64Index([0, 4], dtype='int64'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_label = sentimentBinaryModelTrain.Sentiment.factorize()\n",
    "sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare text for natural language processing\n",
    "# Assign a number to each word in each sentences and replace each word with their respective assigned numbers\n",
    "# Use word embedding to capture the context of the word in a sentence\n",
    "\n",
    "tweet = sentimentBinaryModelTrain.text.values\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(tweet)     # Updates internal vocabulary based on a list of texts\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "encoded_docs = tokenizer.texts_to_sequences(tweet) # Replaces words in sentence with their respective numbers\n",
    "\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200) # Padded sequence is needed as length of tweets varies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "#Long Short-Term Memory Network\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2500/2500 [==============================] - 336s 134ms/step - loss: 0.4975 - accuracy: 0.7630 - val_loss: 0.6954 - val_accuracy: 0.6346\n",
      "Epoch 2/3\n",
      "2500/2500 [==============================] - 333s 133ms/step - loss: 0.4381 - accuracy: 0.8007 - val_loss: 0.5980 - val_accuracy: 0.6924\n",
      "Epoch 3/3\n",
      "2500/2500 [==============================] - 332s 133ms/step - loss: 0.4218 - accuracy: 0.8097 - val_loss: 0.6255 - val_accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_sequence, sentiment_label[0],\n",
    "                   validation_split=0.2, epochs=3, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence to test:We're the party of love, freedom, liberty, and Americanism to name a few \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,  452,    3,  344,   12,   47, 2886,    6,    2,  474,\n",
       "           4,  327]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word = input(\"Enter a sentence to test:\")\n",
    "\n",
    "tw = tokenizer.texts_to_sequences([test_word])\n",
    "tw = pad_sequences(tw,maxlen=200)\n",
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = int(model.predict(tw).round().item())\n",
    "sentiment_label[1][prediction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "import joblib\n",
    "joblib.dump(tokenizer, \"PN_data_tokenizer.joblib\")\n",
    "model.save(\"PNmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train another binary NN for relex-tense vector\n",
    "RT =  df[['text', 'RelaxTense']]\n",
    "RT = RT[RT['RelaxTense'] != 0]\n",
    "#sample 5000 of each relax and tense labels for a balanced set\n",
    "RTBinaryModelTrain = pd.concat([RT[RT.RelaxTense==2].sample(5000),\n",
    "                                RT[RT.RelaxTense==4].sample(5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 1, 1, 1], dtype=int64),\n",
       " Int64Index([2, 4], dtype='int64'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RT_label = RTBinaryModelTrain.RelaxTense.factorize()\n",
    "RT_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare text for natural language processing\n",
    "\n",
    "tweet = RTBinaryModelTrain.text.values\n",
    "tokenizerRT = Tokenizer(num_words=5000)\n",
    "tokenizerRT.fit_on_texts(tweet)     \n",
    "\n",
    "vocab_size = len(tokenizerRT.word_index) + 1\n",
    "\n",
    "encoded_docs = tokenizerRT.texts_to_sequences(tweet) \n",
    "\n",
    "padded_sequenceRT = pad_sequences(encoded_docs, maxlen=200) # Padded sequence is needed as length of tweets varies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "#Long Short-Term Memory Network\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#another binary model to classify between relaxed and tensed\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.5247 - accuracy: 0.7321 - val_loss: 0.2778 - val_accuracy: 0.8755\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.3422 - accuracy: 0.8874 - val_loss: 0.2725 - val_accuracy: 0.8990\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 29s 115ms/step - loss: 0.1248 - accuracy: 0.9601 - val_loss: 0.2386 - val_accuracy: 0.9120\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 29s 114ms/step - loss: 0.0867 - accuracy: 0.9731 - val_loss: 0.2774 - val_accuracy: 0.9160\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 29s 114ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.1963 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_sequenceRT, RT_label[0],\n",
    "                   validation_split=0.2, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence to test:chilling at home\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1663,\n",
       "          32,   89]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word = input(\"Enter a sentence to test:\")\n",
    "\n",
    "tw = tokenizerRT.texts_to_sequences([test_word])\n",
    "tw = pad_sequences(tw,maxlen=200)\n",
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = int(model.predict(tw).round().item())\n",
    "RT_label[1][prediction]\n",
    "#2 means relax 4 means tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tokenizer, \"RT_data_tokenizer.joblib\")\n",
    "model.save(\"RTmodel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#to do:\n",
    "\n",
    "parameter grid for tuning\n",
    "report on NN architecture"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
